{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Javascript, display\n",
    "import numpy as np\n",
    "import pdb\n",
    "from numpy import unravel_index\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import medfilt\n",
    "from ipywidgets import widgets\n",
    "import pandas as pd\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Returns an int array with max values\n",
    "def get_max_values (data, frequency_threshold = 0, sampling_rate = 0):    \n",
    "    # Match the frequency threshold to an index in each column\n",
    "    threshold_index = 0\n",
    "    if frequency_threshold > 0 and sampling_rate > 0:\n",
    "        threshold_index = int(frequency_threshold / ((sampling_rate / 2) / data.shape[0]))\n",
    "    \n",
    "    # Create a magnitude threshold which prevents low values from breaking up curves\n",
    "    magnitude_threshold = 0.00005 * data.max()\n",
    "    \n",
    "    # Create an empty array of the same length as the data array\n",
    "    max_array = np.zeros(data.shape[1], dtype=int)\n",
    "    # Iterate through all columns of the FFT data\n",
    "    previous_max_location = 0\n",
    "    for i in range(0, data.shape[1]):\n",
    "        col = data[threshold_index :, i]\n",
    "        max_location = int(np.argmax(col) + threshold_index)\n",
    "        if data[max_location, i] < magnitude_threshold:\n",
    "            max_location = previous_max_location\n",
    "        max_array[i] = max_location   #Location of the highest value, not the value itself    \n",
    "        previous_max_location = max_location\n",
    "    return max_array\n",
    "\n",
    "\n",
    "# sampling_rate ÷ fft_n represents the number of rows in the data set.\n",
    "# ... fft_n corresponds to the num of rows that would be in the data set if the symmetric half was not removed\n",
    "# ... this is the same as calculating (sampling_rate / 2) ÷ (fft_n / 2)\n",
    "\n",
    "# PRECISION NOTE: Both of these funcitons have a precision of around ~22Hz\n",
    "\n",
    "def index_to_freq(index):\n",
    "    return float(index) * ( float(sampling_rate) / float(fft_n) )\n",
    "\n",
    "def freq_to_index(freq):\n",
    "    return int( float(freq) / ( float(sampling_rate) / float(fft_n) ) )\n",
    "\n",
    "\n",
    "def time_to_index(time, sampling_rate):    \n",
    "    return int(float(time) * float(sampling_rate))\n",
    "\n",
    "def index_to_time(index, sampling_rate):    \n",
    "    return float(index) / float(sampling_rate)\n",
    "\n",
    "\n",
    "def convert_file_to_file_path(atsfile):\n",
    "    prefix = \"Waveform/\"\n",
    "\n",
    "    if atsfile.find(\"ATS24.\") >= 0:\n",
    "        prefix += \"ATS24/\"\n",
    "        tmp = atsfile.split(\".\")\n",
    "        prefix += \"24%02d.wf\"%(int(tmp[1]))\n",
    "\n",
    "    elif atsfile.find(\"ATS24*.\") >= 0:\n",
    "        prefix += \"ATS24v2/\"\n",
    "        tmp = atsfile.split(\".\")\n",
    "        prefix += \"24%02d.wf\"%(int(tmp[1]))\n",
    "\n",
    "    elif atsfile.find(\"ATS26.\") >= 0:\n",
    "        prefix += \"ATS26/\"\n",
    "        tmp = atsfile.split(\".\")\n",
    "        prefix += \"26%02d.wf\"%(int(tmp[1]))\n",
    "\n",
    "    elif atsfile.find(\"Prof\") >= 0:\n",
    "        prefix += \"ISO23747/\"\n",
    "        prefix += atsfile + \".wf\"\n",
    "\n",
    "    elif atsfile.find(\"ISO2678\") >= 0:\n",
    "        prefix += \"ISO26782/\"\n",
    "        tmp = atsfile.split(\".\")\n",
    "        prefix += \"26782%02d.wf\"%(int(tmp[1]))\n",
    "\n",
    "    elif atsfile.find(\"Custom\") >= 0:\n",
    "        tmp = atsfile.split(\".\")\n",
    "        prefix += \"Custom%02d.wf\"%(int(tmp[1]))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return prefix\n",
    "\n",
    "\n",
    "def read_waveform_data(atsfile):\n",
    "\n",
    "    if atsfile is None: # not a PWG waveform\n",
    "        return None\n",
    "\n",
    "    filepath = convert_file_to_file_path(atsfile)\n",
    "\n",
    "    waveform_data = {}\n",
    "    waveform_data[\"Header\"]={}\n",
    "    waveform_data[\"Parameters\"]={}\n",
    "    waveform_data[\"Data\"]=[]\n",
    "    currSection = \"\"\n",
    "    with open(filepath) as f:\n",
    "        data = f.readlines()\n",
    "        for dline in data:\n",
    "            sectionChanged = False\n",
    "            # know the current section\n",
    "            for sec in [\"Header\",\"Parameters\",\"Data\"]:\n",
    "                if dline.find(sec) != -1:\n",
    "                    currSection = sec\n",
    "                    sectionChanged = True \n",
    "            if sectionChanged:\n",
    "                continue \n",
    "                \n",
    "            dline = dline.strip()\n",
    "            if (currSection==\"Header\" or currSection==\"Parameters\") and len(dline)>1:\n",
    "                keyval = dline.split(\"=\")\n",
    "                if keyval[1][0].isdigit():\n",
    "                    keyval[1] = float(keyval[1])\n",
    "                waveform_data[currSection][keyval[0]] = keyval[1]\n",
    "            elif currSection==\"Data\" and len(dline)>1:\n",
    "                waveform_data[currSection].append(float(dline))\n",
    "    return waveform_data\n",
    "\n",
    "\n",
    "# Global variables for use by dropdown call-back\n",
    "global sampling_rate, raw_data, sampling_rate_columns, wav_form, meta, effort\n",
    "# Original sampling rate divided by overlap since there will be a new window every [fft_shift] points \n",
    "# https://db.tt/4lOSyLeO \n",
    "\n",
    "# FFT Variables\n",
    "# Number of points in each FFT window\n",
    "fft_n = 2048\n",
    "\n",
    "# Number of points each subsequent window is shifted\n",
    "fft_shift = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open JSON file containing info about audio files\n",
    "\n",
    "# data_path = 'audio_curve_data/Final_Data/'\n",
    "# json_file = data_path + '010.json'\n",
    "\n",
    "def load_json_data(data_path, json_file):\n",
    "    global audio_files\n",
    "    with open(json_file) as audio_data_json:    \n",
    "        audio_files_data = json.load(audio_data_json)\n",
    "\n",
    "    # Retrieve the name of all audio files for dropdown\n",
    "    tests = audio_files_data['Tests']\n",
    "    audio_files = {}\n",
    "    audio_files_list = []\n",
    "    for i in range(0, len(tests)):\n",
    "        # IGNORE ALL YELLOW SIDESTACK TESTS\n",
    "        if tests[i]['Sidestack'] != 'Sidestack C (Yellow)':\n",
    "            test = tests[i]\n",
    "            efforts = test['Efforts']\n",
    "            for j in range(0, len(efforts)):\n",
    "                effort = efforts[j]\n",
    "                effort_data = {}\n",
    "                file_name = effort['RecordedAudioFilenameForEffort']\n",
    "\n",
    "                effort_data['WavFile'] = file_name\n",
    "\n",
    "                ats_string = test['PWGFile']\n",
    "                effort_data['PWGFile'] = ats_string\n",
    "\n",
    "                if ats_string in audio_files:\n",
    "                    next_val = 2\n",
    "                    while ats_string + str(next_val) in audio_files:\n",
    "                        next_val += 1\n",
    "                    test_string = ats_string + '-' + str(next_val)\n",
    "                else:\n",
    "                    test_string = test['PWGFile']\n",
    "\n",
    "                sidestack = test['Sidestack']\n",
    "                downstream = test['DownstreamTube']\n",
    "                ball = test['Ball']\n",
    "                mouthpiece = test['Mouthpiece']\n",
    "                effort_data['Metadata'] = sidestack + downstream + mouthpiece + ball\n",
    "                effort_data['ID'] = test_string\n",
    "\n",
    "                audio_files[test_string] = effort_data\n",
    "                audio_files_list.append(test_string)\n",
    "\n",
    "\n",
    "    # DEFAULT AUDIO FILE - If this file is changed, change the default file shown by the dropdown as well\n",
    "    # Import data from an audio file, save sampling rate and raw data\n",
    "    # default_file = '1464278801.365085.wav'\n",
    "\n",
    "    audio_files_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_algorithm():\n",
    "    # Plot the raw spectrogram of the audio data \n",
    "    f = plt.figure(figsize=(15,10)) \n",
    "    plt.style.use('ggplot') \n",
    "\n",
    "    data, data_freq, data_time, _ = plt.specgram(raw_data, NFFT=fft_n, Fs=sampling_rate, noverlap=(fft_n-fft_shift) ) \n",
    "    # data is basically a matrix of magnitudes\n",
    "    # data_freq is a single column with the same number of rows as data where each row is a frequency (0 - fs/2) \n",
    "    # data_time is an array of columns the same length as |ata where each index contains the time value at that column (0 - ~19) \n",
    "    data[data==0] = 0.0001 \n",
    "\n",
    "\n",
    "    # Clear original figure \n",
    "    f.clear()\n",
    "\n",
    "    # Plot a customized figure\n",
    "    ax = plt.subplot(1,1,1) \n",
    "    ax.pcolorfast(data_time, data_freq, np.log(data+0.00001), cmap=plt.cm.bone) \n",
    "    plt.grid()\n",
    "    plt.savefig('Results/Figures/' + effort['ID'] + ' - [1] Raw' + '.png')\n",
    "    f.clear()\n",
    "    \n",
    "    frequency_threshold = 200\n",
    "    max_values = get_max_values(data, frequency_threshold, sampling_rate)\n",
    "\n",
    "    med_window_length = 31\n",
    "    max_values = medfilt(max_values, med_window_length)\n",
    "\n",
    "    sg_window_length = 21\n",
    "    poly_order = 1\n",
    "    max_values = savgol_filter(max_values, sg_window_length, poly_order, mode='mirror')\n",
    "\n",
    "    max_values = max_values.round(decimals=0)\n",
    "    max_values = max_values.astype(int)\n",
    "\n",
    "    # Plot Modification\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    ax.pcolorfast(data_time, data_freq, np.log(data), cmap=plt.cm.bone)\n",
    "    ax.plot(data_time, max_values*sampling_rate/fft_n)\n",
    "    # max_values is a 1D array containing the vertical index which represents the max value for any given slice\n",
    "    # ... because this value is NOT a frequency, we must map it to the correct frequency by multiplying the value by \n",
    "    # ... sampling_rate/fft_n which is generated by the following:\n",
    "    # ... The FFT returns a symmetric graph from 0 to fft_n, but because it's symmetric, half must be removed (fft_n/2)\n",
    "    # ... then to map a frequency to an index, the sampling rate must be divided by 2 (fs/2)... finally, to map the two,\n",
    "    # ... any index from fft_n/2 must be mapped to fs/2, resuling in fs/2 ÷ fft_n/2 OR fs/fft_n\n",
    "\n",
    "    # Calculate the overall energy by summing each column\n",
    "    cols = 0\n",
    "    db_data = np.log(data[(data_freq>200) & (data_freq<4000),:]) \n",
    "    energy = np.max(db_data,axis=cols)\n",
    "    db_min = np.percentile(energy,10)\n",
    "    energy = energy - db_min\n",
    "\n",
    "    energy = np.mean(data, axis=cols)\n",
    "\n",
    "    # Graph it on top of the spectrogram\n",
    "    ax2 = ax.twinx()\n",
    "    plt.ylim(0, max(energy))\n",
    "    ax2.plot(data_time, energy, 'g')\n",
    "\n",
    "\n",
    "    # Create variables for various features (curves)\n",
    "\n",
    "    #REMOVE\n",
    "    # Curve which will be used for the analysis\n",
    "    # data_curve = max_values*sampling_rate/fft_n\n",
    "    # data_curve = max_values\n",
    "    # The data is multiplied by the sampling_rate/fft_n to map y-indices to frequencies\n",
    "\n",
    "    # whistle_endpoints: the whistle at the beginning and end of the test\n",
    "    whistle_endpoints = np.empty(data.shape[1])\n",
    "    whistle_endpoints[:] = np.nan\n",
    "\n",
    "    # whistle_midsection: the whistle (during vortex) after jumping in frequency\n",
    "    whistle_midsection = np.empty(data.shape[1])\n",
    "    whistle_midsection[:] = np.nan\n",
    "\n",
    "    # whistle_combined_normalized: a curve combining all whistle components, including a normalized midsection\n",
    "    whistle_combined_normalized = np.empty(data.shape[1])\n",
    "    whistle_combined_normalized[:] = np.nan\n",
    "\n",
    "    # vortex_fundamental: a curve representing the extracted vortex curve\n",
    "    vortex_fundamental = np.empty(data.shape[1])\n",
    "    vortex_fundamental[:] = np.nan\n",
    "\n",
    "    # vortex_harmonics: an array for additional vortex harmonics (should they be detected)\n",
    "    vortex_harmonics = []\n",
    "\n",
    "\n",
    "\n",
    "    # Find point of max energy from the energy curve\n",
    "    max_energy_loc = np.argmax(energy[0 : int(len(energy) * .8)])\n",
    "    max_energy = energy[max_energy_loc]\n",
    "    # max_energy_time = index_to_time(max_energy_loc, sampling_rate_columns)\n",
    "\n",
    "\n",
    "    # Find # of index points in 1/2 second... create window of max_energy_location ± index\n",
    "    search_window_time = 0.25\n",
    "    search_window_shift = time_to_index(search_window_time, sampling_rate_columns)\n",
    "    search_window_begin = max_energy_loc - search_window_shift\n",
    "    search_window_end = max_energy_loc + search_window_shift + 1\n",
    "    # +1 was added to account for python array indexing\n",
    "\n",
    "\n",
    "    # Search through max_values to find the temp point of max magnitude (in the search window)\n",
    "    init_max_mag_x = np.argmax(max_values[search_window_begin : search_window_end]) + search_window_begin\n",
    "    init_max_mag_y = max_values[init_max_mag_x]\n",
    "    midsection_lookahead = 0\n",
    "\n",
    "    # Try to find top whistle if max_values didn't detect it\n",
    "\n",
    "    if index_to_freq(init_max_mag_y) < 3000.0:\n",
    "        midpoint = init_max_mag_x\n",
    "        expansion = 10\n",
    "        window_left = midpoint - expansion\n",
    "        window_right = midpoint + expansion + 1\n",
    "        window_bottom = freq_to_index(4500.0)\n",
    "        window_top = freq_to_index(6000.0)\n",
    "\n",
    "        search_area = data[window_bottom : window_top, window_left : window_right]\n",
    "\n",
    "        top_whistle_peak = unravel_index(search_area.argmax(), search_area.shape)\n",
    "\n",
    "        init_max_mag_y = top_whistle_peak[0] + window_bottom\n",
    "        init_max_mag_x = top_whistle_peak[1] + window_left\n",
    "\n",
    "        midsection_lookahead = 25\n",
    "        print 'Performing alternate search for whistle midsection due to anomaly'\n",
    "\n",
    "    # init_max_mag_time = index_to_time(init_max_mag_x, sampling_rate_columns)\n",
    "\n",
    "\n",
    "    # Follow this curve within a band of ±30Hz and find end points to determine whistle mid-section\n",
    "    search_index = init_max_mag_x - 1\n",
    "\n",
    "\n",
    "\n",
    "    def identify_curve(data, curve, x_index, y_index, band_index, signal_threshold = 5.0, lookahead = 5):\n",
    "        def get_signal_significance():\n",
    "            if x_index >= data.shape[1] or x_index < 0:\n",
    "                return 0.0, 0\n",
    "\n",
    "            # INNER\n",
    "            # Inner mean is the mean of the values surrounding the max within ± X Hz\n",
    "            inner_lower_y = y_index - band_index\n",
    "            if inner_lower_y < 0:\n",
    "                inner_lower_y = 0\n",
    "\n",
    "            inner_upper_y = y_index + band_index + 1\n",
    "            if inner_upper_y >= data.shape[0]:\n",
    "                inner_upper_y = data.shape[0] - 1\n",
    "\n",
    "            inner_window = data[inner_lower_y : inner_upper_y, x_index]\n",
    "            inner_mean = np.mean(inner_window)\n",
    "    #         inner_mean = np.max(inner_window)\n",
    "\n",
    "            # OUTER\n",
    "            outer_band_index = band_index * 3\n",
    "            outer_lower_y = inner_lower_y - outer_band_index\n",
    "            if outer_lower_y < 0:\n",
    "                outer_lower_y = 0\n",
    "\n",
    "            outer_upper_y = inner_upper_y + outer_band_index\n",
    "            if outer_upper_y > data.shape[0]:\n",
    "                outer_upper_y = data.shape[0] - 1\n",
    "\n",
    "            lower = data[outer_lower_y : inner_lower_y, x_index]\n",
    "            upper = data[inner_upper_y : outer_upper_y, x_index]\n",
    "            outer_window = np.concatenate([lower, upper], axis=0)\n",
    "\n",
    "            outer_mean = np.mean(outer_window)\n",
    "    #         outer_mean = np.max(outer_window)\n",
    "\n",
    "            max_y_loc = np.argmax(inner_window) + inner_lower_y\n",
    "\n",
    "\n",
    "            return inner_mean/outer_mean, max_y_loc\n",
    "\n",
    "        curve_start = 0\n",
    "        curve_end = len(data) - 1\n",
    "\n",
    "        # Save original values\n",
    "        orig_x = x_index\n",
    "        orig_y = y_index\n",
    "        orig_band_index = band_index\n",
    "\n",
    "        # TRACE CURVE BACKWARDS\n",
    "        signal_significance = 100.0\n",
    "        end_found = False\n",
    "        while not end_found:\n",
    "    #         if x_index <= 0:\n",
    "    #             break\n",
    "            signal_significance, max_y_loc = get_signal_significance()\n",
    "            if signal_significance >= signal_threshold:\n",
    "                # Signal is still significant, continue following\n",
    "                curve[x_index] = max_y_loc\n",
    "                x_index -= 1\n",
    "                y_index = max_y_loc\n",
    "                # Resetting band in case it needed to be adjusted by the expanded search\n",
    "                band_index = orig_band_index\n",
    "            else:\n",
    "                # Signal is no longer significant, look ahead and continue\n",
    "                end_found = True\n",
    "                curve_start = x_index + 1\n",
    "\n",
    "                for i in range(0, lookahead):\n",
    "                    x_index -= 1\n",
    "    #                 if x_index > 0:\n",
    "                    signal_significance, max_y_loc = get_signal_significance()\n",
    "                    if signal_significance >= signal_threshold:\n",
    "                        end_found = False\n",
    "                        # Store the y-value so it can be found on the next full pass\n",
    "                        y_index = max_y_loc\n",
    "\n",
    "                            # Return back to index before so the next loop grabs the value\n",
    "                        band_index = orig_band_index\n",
    "                        break\n",
    "    #                 else:\n",
    "    #                     break\n",
    "\n",
    "                if end_found:\n",
    "                    x_index = curve_start\n",
    "                    band_index *= 2\n",
    "                    for i in range(0, lookahead):\n",
    "                        x_index -= 1\n",
    "                        signal_significance, max_y_loc = get_signal_significance()\n",
    "                        if signal_significance >= signal_threshold:\n",
    "                            end_found = False\n",
    "                            # Store the y-value so it can be found on the next full pass\n",
    "                            y_index = max_y_loc\n",
    "\n",
    "                            # Return back to index before so the next loop grabs the value\n",
    "                            break\n",
    "\n",
    "                if end_found:\n",
    "                    x_index = curve_start\n",
    "                    band_index = orig_band_index\n",
    "                    band_index /= 2\n",
    "                    for i in range(0, lookahead):\n",
    "                        x_index -= 1\n",
    "                        signal_significance, max_y_loc = get_signal_significance()\n",
    "                        if signal_significance >= signal_threshold:\n",
    "                            end_found = False\n",
    "                            # Store the y-value so it can be found on the next full pass\n",
    "                            y_index = max_y_loc\n",
    "\n",
    "                            # Return back to index before so the next loop grabs the value\n",
    "                            break \n",
    "\n",
    "        # TRACE CURVE FORWARDS\n",
    "        x_index = orig_x\n",
    "        y_index = orig_y\n",
    "        band_index = orig_band_index\n",
    "\n",
    "        signal_significance = 100.0\n",
    "        end_found = False\n",
    "        while not end_found:\n",
    "            signal_significance, max_y_loc = get_signal_significance()\n",
    "            if signal_significance >= signal_threshold:\n",
    "                # Signal is still significant, continue following\n",
    "                curve[x_index] = max_y_loc\n",
    "                x_index += 1\n",
    "                y_index = max_y_loc\n",
    "                # Resetting band in case it needed to be adjusted by the expanded search\n",
    "                band_index = orig_band_index\n",
    "            else:\n",
    "                # Signal is no longer significant, look ahead and continue\n",
    "                end_found = True\n",
    "                curve_end = x_index - 1\n",
    "\n",
    "                for i in range(0, lookahead):\n",
    "                    x_index += 1\n",
    "                    signal_significance, max_y_loc = get_signal_significance()\n",
    "                    if signal_significance >= signal_threshold:\n",
    "                        end_found = False\n",
    "                        y_index = max_y_loc\n",
    "                        break\n",
    "\n",
    "                if end_found:\n",
    "                    band_index *= 2\n",
    "                    x_index = curve_end\n",
    "                    for i in range(0, lookahead):\n",
    "                        x_index += 1\n",
    "                        signal_significance, max_y_loc = get_signal_significance()\n",
    "                        if signal_significance >= signal_threshold:\n",
    "                            end_found = False\n",
    "                            y_index = max_y_loc\n",
    "                            break\n",
    "\n",
    "                if end_found:\n",
    "                    band_index = orig_band_index\n",
    "                    band_index /= 2\n",
    "                    x_index = curve_end\n",
    "                    for i in range(0, lookahead):\n",
    "                        x_index += 1\n",
    "                        signal_significance, max_y_loc = get_signal_significance()\n",
    "                        if signal_significance >= signal_threshold:\n",
    "                            end_found = False\n",
    "                            y_index = max_y_loc\n",
    "                            break\n",
    "\n",
    "\n",
    "        return curve_start, curve_end\n",
    "\n",
    "\n",
    "    # When investigating a dead signal, attempt to figure out where the next point SHOULD be...\n",
    "    # - Slope of past 3 points\n",
    "    # - Slope since origin\n",
    "    # - Regression of curve so far\n",
    "\n",
    "\n",
    "    x_index = init_max_mag_x\n",
    "    y_index = init_max_mag_y\n",
    "\n",
    "    band_index = freq_to_index(50.0)\n",
    "    if midsection_lookahead > 0:\n",
    "        band_index = freq_to_index(125.0)\n",
    "\n",
    "\n",
    "    # WHISTLE MIDSECTION\n",
    "\n",
    "    curve_start, curve_end = identify_curve(data, whistle_midsection, x_index, y_index, band_index, lookahead=midsection_lookahead)\n",
    "    midsection_start = curve_start\n",
    "    midsection_end = curve_end\n",
    "\n",
    "\n",
    "    band_index = freq_to_index(50.0)\n",
    "\n",
    "\n",
    "    # FRONT WHISTLE\n",
    "\n",
    "    # Find a relevant y-index for for the beginning of the front whistle\n",
    "    front_y_index = int(whistle_midsection[midsection_start] / 3)\n",
    "\n",
    "    window_bottom = front_y_index - band_index\n",
    "    window_top = front_y_index + band_index + 1\n",
    "    window_left = midsection_start - 10\n",
    "    window_right = midsection_start + 11\n",
    "\n",
    "    front_search_area = data[window_bottom : window_top, window_left : window_right]\n",
    "    front_peak = unravel_index(front_search_area.argmax(), front_search_area.shape)\n",
    "\n",
    "    front_y_index = front_peak[0] + window_bottom\n",
    "    front_x_index = front_peak[1] + window_left\n",
    "\n",
    "\n",
    "    curve_start, curve_end = identify_curve(data, whistle_endpoints, front_x_index, front_y_index, band_index, lookahead=10)\n",
    "    front_whistle_start = curve_start\n",
    "    front_whistle_end = curve_end\n",
    "\n",
    "    if np.isnan(front_whistle_start):\n",
    "        front_whistle_start = midsection_start\n",
    "        front_whistle_end = midsection_start\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # BACK WHISTLE\n",
    "\n",
    "    # Find a relevant y-index for for the beginning of the back whistle\n",
    "    end_y_index = int(whistle_midsection[midsection_end] / 3)\n",
    "\n",
    "    window_bottom = end_y_index - band_index*2\n",
    "    window_top = end_y_index + band_index*2 + 1\n",
    "    window_left = midsection_end - 10\n",
    "    window_right = midsection_end + 11\n",
    "\n",
    "    back_search_area = data[window_bottom : window_top, window_left : window_right]\n",
    "    back_peak = unravel_index(back_search_area.argmax(), back_search_area.shape)\n",
    "\n",
    "    back_y_index = back_peak[0] + window_bottom\n",
    "    back_x_index = back_peak[1] + window_left\n",
    "\n",
    "    curve_start, curve_end = identify_curve(data, whistle_endpoints, back_x_index, back_y_index, band_index) #, lookahead=10)\n",
    "\n",
    "    # if np.isnan(back_whistle_start):\n",
    "    #     curve_start, curve_end = identify_curve(data, whistle_endpoints, midsection_end, front_y_index, band_index) #, lookahead=10)\n",
    "\n",
    "    back_whistle_start = curve_start\n",
    "    back_whistle_end = curve_end\n",
    "\n",
    "    if np.isnan(back_whistle_start):\n",
    "        back_whistle_start = midsection_end\n",
    "        back_whistle_end = midsection_end\n",
    "\n",
    "\n",
    "\n",
    "    # ADDITIONAL WHISTLE DATA POINTS\n",
    "    whistle_min = np.nan\n",
    "    if np.isnan(whistle_endpoints).all():\n",
    "        whistle_min = int(np.nanmin(whistle_midsection))\n",
    "    else:\n",
    "        whistle_min = int(np.nanmin(whistle_endpoints))\n",
    "\n",
    "\n",
    "    whistle_max = int(np.nanmax(whistle_midsection))\n",
    "\n",
    "\n",
    "    midsection_min = int(np.nanmin(whistle_midsection))\n",
    "    midsection_max = int(np.nanmax(whistle_midsection))\n",
    "\n",
    "\n",
    "    def process_curve(curve, curve_start, curve_end, search_range_start, search_range_end, outer_range_start, outer_range_end):\n",
    "        if np.isfinite(outer_range_start) and curve_start < outer_range_start:\n",
    "            curve[ : outer_range_start] = np.nan\n",
    "            curve_start = outer_range_start\n",
    "\n",
    "        if np.isfinite(outer_range_end) and curve_end > outer_range_end:\n",
    "            curve[outer_range_end + 1: ] = np.nan\n",
    "            curve_end = outer_range_start\n",
    "\n",
    "        curve[curve <= 10] = np.nan\n",
    "\n",
    "        for i in range(curve_end, curve_start - 1, -1):\n",
    "            if np.isfinite(curve[i]) == True:\n",
    "                curve_end = i\n",
    "                break\n",
    "\n",
    "        curve_peak_x = np.nanargmax(curve[search_range_start : search_range_end]) + search_range_start\n",
    "        curve_peak_y = np.nanmax(curve[search_range_start : search_range_end])\n",
    "\n",
    "\n",
    "        window = 10\n",
    "\n",
    "        start_front_idx = curve_peak_x - int((curve_peak_x - curve_start) * .3)\n",
    "        start_back_idx = curve_peak_x + int((outer_range_end - curve_peak_x) * .3)\n",
    "\n",
    "        # Cough detection\n",
    "        back_idx_buffer = 5\n",
    "        if start_back_idx + back_idx_buffer < curve_end:\n",
    "            second_max = np.nanargmax(curve[start_back_idx + 5 : curve_end]) + start_back_idx + 5\n",
    "            back_midpoint = np.min([start_back_idx + int((curve_end - start_back_idx) * .5), outer_range_end])\n",
    "\n",
    "            if second_max < back_midpoint:\n",
    "                start_back_idx = second_max + int((back_midpoint - second_max) * .3)\n",
    "\n",
    "        for i in range(start_front_idx, curve_start, -1):\n",
    "            if i - window < curve_start:\n",
    "                slope = np.nanmean(np.diff(curve[curve_start : i + 1]))\n",
    "                if slope < 0:\n",
    "                    curve_start = i\n",
    "                    break\n",
    "            else:\n",
    "                slope = np.nanmean(np.diff(curve[i - window : i + 1]))\n",
    "                if slope < 0:\n",
    "                    curve_start = i - window + 1\n",
    "                    break\n",
    "\n",
    "\n",
    "        for i in range(start_back_idx, curve_end + 1, 1):\n",
    "            if i + window > curve_end:\n",
    "                slope = np.nanmean(np.diff(curve[i : curve_end + 1]))\n",
    "                if slope > 0:\n",
    "                    curve_end = i\n",
    "                    break\n",
    "            else:\n",
    "                slope = np.nanmean(np.diff(curve[i : i + window + 1]))\n",
    "\n",
    "                if slope > 0:\n",
    "                    curve_end = i + window - 1\n",
    "                    break\n",
    "\n",
    "\n",
    "        curve[ : curve_start] = np.nan\n",
    "        curve[curve_end : ] = np.nan\n",
    "\n",
    "        return curve, curve_start, curve_end\n",
    "\n",
    "\n",
    "    # Define initial search area for vortex fundamental\n",
    "    area_width = back_whistle_start - front_whistle_end\n",
    "    midpoint = front_whistle_end + area_width/2\n",
    "    expansion = int(area_width*.35)\n",
    "    window_start = midpoint - expansion\n",
    "    window_end = midpoint + expansion\n",
    "\n",
    "    bottom_noise_index = 20\n",
    "    search_area = data[bottom_noise_index : midsection_min - 1, window_start : window_end]\n",
    "    # search_area = data[20 : midsection_min - 1, front_whistle_end : back_whistle_start]\n",
    "    # search_area = data[20 : whistle_min - 1, front_whistle_end : back_whistle_start]\n",
    "\n",
    "    # If front whistle continues across entire test\n",
    "    if front_whistle_end > back_whistle_end or search_area.shape[1] <= 5:\n",
    "        print \"Search area modified due to whistle anomaly\"\n",
    "        search_area = data[bottom_noise_index : whistle_min - 1, midsection_start : midsection_end]\n",
    "        window_start = midsection_start\n",
    "\n",
    "    peak_vortex_mag = unravel_index(search_area.argmax(), search_area.shape)\n",
    "\n",
    "    peak_vortex_mag_y = peak_vortex_mag[0] + bottom_noise_index\n",
    "    peak_vortex_mag_x = peak_vortex_mag[1] + window_start\n",
    "\n",
    "    # Modifying band_index significantly impacts the significance detection\n",
    "\n",
    "    midsection_range = midsection_max - midsection_min\n",
    "\n",
    "    core_data = np.copy(data)\n",
    "\n",
    "\n",
    "    if front_whistle_start and front_whistle_end:\n",
    "        core_data[whistle_min - 1 : , front_whistle_start - 1 : front_whistle_end + 1] = np.nan\n",
    "\n",
    "    if back_whistle_start and back_whistle_end:\n",
    "        core_data[whistle_min - 1 : , back_whistle_start - 1 : back_whistle_end + 1] = np.nan\n",
    "\n",
    "    best_curve_weight = 0.0\n",
    "\n",
    "    start_freq = 50.0\n",
    "    stop_freq = 300.0\n",
    "    step_freq = 25.0\n",
    "\n",
    "    range_end = int((stop_freq - start_freq)/step_freq + 1)\n",
    "\n",
    "    # Determine best vortex\n",
    "    vortex_fundamentals = []\n",
    "    for i in range(0, range_end, 1):\n",
    "        curve = np.empty(data.shape[1])\n",
    "        curve[:] = np.nan\n",
    "\n",
    "        band_index = freq_to_index(start_freq + step_freq * i)\n",
    "\n",
    "        curve_start, curve_end = identify_curve(core_data, curve, peak_vortex_mag_x, peak_vortex_mag_y, band_index, signal_threshold=1.2, lookahead = 10)\n",
    "        raw_curve = np.copy(curve)\n",
    "\n",
    "\n",
    "\n",
    "        if curve_start < curve_end:\n",
    "            curve, curve_start, curve_end = process_curve(curve, curve_start, curve_end, midsection_start, midsection_end, front_whistle_start, back_whistle_end)\n",
    "        curve_data = {'curve': curve, 'raw_curve': raw_curve, 'curve_start': curve_start, 'curve_end': curve_end}\n",
    "        vortex_fundamentals.append(curve_data)\n",
    "\n",
    "        num_finite = np.sum(np.isfinite(curve[curve_start : curve_end + 1]))\n",
    "        curve_length = curve_end - curve_start\n",
    "        if curve_length == 0:\n",
    "            curve_density = 0\n",
    "            curve_weight = 0\n",
    "        else:\n",
    "            curve_density = float(num_finite) / float(curve_length)\n",
    "            curve_weight = float(curve_length) * float(curve_density)\n",
    "\n",
    "        if  curve_weight > best_curve_weight:\n",
    "            best_curve_weight = curve_weight\n",
    "            best_curve = i\n",
    "\n",
    "    print 'Best Curve Identified with freq %0.1f Hz and weight %.1f' % (start_freq + step_freq * best_curve, best_curve_weight * 100)\n",
    "    best_curve_data = vortex_fundamentals[best_curve]\n",
    "    vortex_fundamental = best_curve_data['curve']\n",
    "    vortex_start = best_curve_data['curve_start']\n",
    "    vortex_end = best_curve_data['curve_end']\n",
    "\n",
    "\n",
    "    # NOTE: When trying to graph curves, either use the data_freq array as the y-axis labels\n",
    "    # ... or multiply the data by sampling_rate/fft_n to map indices to frequencies\n",
    "    data_curve = max_values * sampling_rate/fft_n\n",
    "\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "    ax.plot(max_values, 'r')\n",
    "\n",
    "    # ax.plot(search_window_begin, max_values[search_window_begin], 'og')\n",
    "    # ax.text(search_window_begin, max_values[search_window_begin], 'Search Start')\n",
    "    # ax.plot(search_window_end, max_values[search_window_end], 'or')\n",
    "    # ax.text(search_window_end, max_values[search_window_end], 'Search Stop')\n",
    "\n",
    "    # ax.plot(init_max_mag_x, init_max_mag_y, 'or')\n",
    "    # ax.text(init_max_mag_x, init_max_mag_y - init_max_mag_y*0.01, 'Max Mag (Init)')\n",
    "\n",
    "\n",
    "    # ax.plot(curve_end, init_y_index, 'or')\n",
    "    # ax.text(curve_end, init_y_index, 'WAT')\n",
    "    ax.plot(whistle_midsection, 'b')\n",
    "    ax.plot(whistle_endpoints, 'b')\n",
    "\n",
    "    # ax.plot(vortex_fundamental_copy, 'y')\n",
    "    ax.plot(vortex_fundamental, 'b')\n",
    "    # ax.plot(vortex_peak_x, vortex_peak_y, 'or', alpha = .3)\n",
    "    # ax.plot(start_front_idx, vortex_fundamental[start_front_idx], 'og', alpha = .3)\n",
    "    # ax.plot(start_back_idx, vortex_fundamental[start_back_idx], 'og', alpha = .2)\n",
    "    # ax.plot(back_x_index, back_y_index, 'ob', alpha = .2)\n",
    "\n",
    "\n",
    "    # Add time as a second x-axis\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(0, data_time[-1])\n",
    "    ax2.set_xlabel('Time')\n",
    "\n",
    "\n",
    "    # Add energy as a second y-axis\n",
    "    ax3 = ax.twinx()\n",
    "    ax3.set_ylabel('Energy')\n",
    "\n",
    "    ax3.plot(energy, 'g')\n",
    "    ax3.plot(max_energy_loc, max_energy, 'ob')\n",
    "    ax3.text(max_energy_loc, max_energy + 0.01*max_energy, 'Max Energy Value')\n",
    "\n",
    "\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "    # data[20 : midsection_min - 1, midpoint - expansion : midpoint + expansion] *= 100\n",
    "\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    # ax = plt.subplot(1,1,1)\n",
    "    data[:bottom_noise_index, :] *= .1\n",
    "\n",
    "    ax.pcolorfast(np.log(data), cmap=plt.cm.bone)\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.pcolorfast(np.log(data), cmap=plt.cm.bone)\n",
    "\n",
    "\n",
    "    ax.plot(whistle_midsection, 'b')\n",
    "    ax.plot(whistle_endpoints, 'b')\n",
    "\n",
    "    ax.plot(vortex_fundamentals[1]['curve'], 'r')\n",
    "    ax.plot(vortex_fundamentals[1]['raw_curve'], 'y', linewidth = 2.0)\n",
    "\n",
    "\n",
    "\n",
    "    # for curve in vortex_harmonics:\n",
    "    #     ax.plot(curve, 'g')\n",
    "\n",
    "\n",
    "    ax.plot(vortex_fundamental, 'g')\n",
    "\n",
    "\n",
    "    plt.savefig('Results/Figures/' + effort['ID'] + ' - [3] Curve Following Comparison' + '.png')\n",
    "    f.clear()\n",
    "\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "    # back_search_area *= 10000\n",
    "\n",
    "    # ax = plt.subplot(2,1,1)\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    ax.pcolorfast(np.log(data), cmap=plt.cm.bone)\n",
    "\n",
    "    ax.plot(whistle_midsection, 'b')\n",
    "    ax.plot(whistle_endpoints, 'b')\n",
    "\n",
    "    ax.plot(vortex_fundamental, 'r')\n",
    "\n",
    "    plt.savefig('Results/Figures/' + effort['ID'] + ' - [2] Curve Following' + '.png')\n",
    "    f.clear()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create blended whistle signal\n",
    "    whistle_combined_normalized = np.copy(whistle_endpoints)\n",
    "    first_whistle_point = min(front_whistle_start, front_whistle_end, back_whistle_start, back_whistle_end)\n",
    "\n",
    "    if first_whistle_point > midsection_start:\n",
    "        diff = np.nanmin(whistle_midsection) - whistle_endpoints[back_whistle_start]\n",
    "        whistle_combined_normalized[midsection_start : back_whistle_start + 1] = whistle_midsection[midsection_start : back_whistle_start + 1] - diff\n",
    "    elif front_whistle_end < back_whistle_start:\n",
    "        diff = np.nanmin(whistle_midsection) - np.nanmax([whistle_endpoints[front_whistle_end], whistle_endpoints[back_whistle_start]])\n",
    "        whistle_combined_normalized[front_whistle_end : back_whistle_start + 1] = whistle_midsection[front_whistle_end : back_whistle_start + 1] - diff\n",
    "\n",
    "\n",
    "\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    ax.pcolorfast(np.log(data), cmap=plt.cm.bone)\n",
    "    ax.plot(whistle_combined_normalized)\n",
    "    plt.savefig('Results/Figures/' + effort['ID'] + ' - [5] Blended Whistle' + '.png')\n",
    "    f.clear()\n",
    "\n",
    "    crop_start = 0\n",
    "\n",
    "    temp = np.isfinite(whistle_midsection) | np.isfinite(whistle_endpoints) | np.isfinite(vortex_fundamental)\n",
    "\n",
    "    for i in range(0, len(temp)):\n",
    "        if temp[i] == 1:\n",
    "            crop_start = max(i-300,0)\n",
    "\n",
    "            break\n",
    "\n",
    "    cropped_midsection = whistle_midsection[crop_start :]\n",
    "    cropped_endpoints = whistle_endpoints[crop_start :]\n",
    "    cropped_fundamental = vortex_fundamental[crop_start :]\n",
    "    cropped_blended_whistle = whistle_combined_normalized[crop_start :]\n",
    "\n",
    "\n",
    "    # plot the waveform of the test\n",
    "    time = np.arange(0,len(wav_form[\"Data\"])).astype(np.float)/float(wav_form[\"Header\"][\"Freq\"])\n",
    "    wav_fs = float(wav_form[\"Header\"][\"Freq\"])\n",
    "\n",
    "\n",
    "    # add proper axes\n",
    "    if wav_form[\"Header\"][\"Type\"] ==\"VT\":\n",
    "\n",
    "        volume = np.array(wav_form[\"Data\"]).astype(np.float)\n",
    "        flow = (volume[1:]-volume[:-1])*wav_fs\n",
    "        flow = np.hstack(([0],flow))\n",
    "        # apply filter to calced flow rate\n",
    "        flow = savgol_filter(flow, 21, 2 )\n",
    "\n",
    "    elif wav_form[\"Header\"][\"Type\"] ==\"FT\":\n",
    "        flow = np.array(wav_form[\"Data\"]).astype(np.float)\n",
    "        volume = np.cumsum(flow/wav_fs)\n",
    "\n",
    "    orig_flow = flow\n",
    "\n",
    "\n",
    "    x1 = cropped_fundamental\n",
    "    x2 = cropped_endpoints\n",
    "    x3 = cropped_midsection\n",
    "    x4 = cropped_blended_whistle\n",
    "\n",
    "    # make same sampling rate\n",
    "    flow = orig_flow\n",
    "    flow = resample(flow,float(len(flow))/float(wav_fs)*float(sampling_rate_columns))\n",
    "\n",
    "    x1_m = np.nanargmax(x1)\n",
    "    f_m = np.nanargmax(flow)\n",
    "\n",
    "\n",
    "    # align maxima\n",
    "    if x1_m>f_m:\n",
    "        flow = np.hstack((np.ones((x1_m-f_m,))*np.nan,flow))\n",
    "    else:\n",
    "        x1 = np.hstack((np.ones((f_m-x1_m,))*np.nan,x1))\n",
    "        x2 = np.hstack((np.ones((f_m-x1_m,))*np.nan,x2))\n",
    "        x3 = np.hstack((np.ones((f_m-x1_m,))*np.nan,x3))\n",
    "        x4 = np.hstack((np.ones((f_m-x1_m,))*np.nan,x4))\n",
    "\n",
    "    # make equal lengths\n",
    "    if len(x1)>len(flow):\n",
    "        flow = np.hstack((flow,np.ones((len(x1)-len(flow),))*np.nan))\n",
    "    else:\n",
    "        x1 = np.hstack((x1,np.ones((len(flow)-len(x1),))*np.nan))\n",
    "        x2 = np.hstack((x2,np.ones((len(flow)-len(x2),))*np.nan))\n",
    "        x3 = np.hstack((x3,np.ones((len(flow)-len(x3),))*np.nan))\n",
    "        x4 = np.hstack((x4,np.ones((len(flow)-len(x4),))*np.nan))\n",
    "\n",
    "    volume = np.cumsum(flow/sampling_rate_columns)\n",
    "    df = pd.DataFrame(np.vstack((flow,volume,x1,x2,x3,x4)).T,columns=['flow','volume','vortex','side_f','side_h1','side_blended'])\n",
    "\n",
    "    df['PWG'] = str(wav_form['Header']['Group'])+str(wav_form['Header']['Name'])\n",
    "    df['meta'] = meta\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    dftmp = df[['flow','vortex']]/df[['flow','vortex']].max()\n",
    "    dftmp.plot()\n",
    "    plt.savefig('Results/Figures/' + effort['ID'] + ' - [4] Flow vs Vortex' + '.png')\n",
    "    f.clear()\n",
    "\n",
    "    # effort = audio_files[json_selector.value]\n",
    "    file_name = effort['WavFile']\n",
    "\n",
    "    df.to_csv('Results/' + effort['ID'] + ' - ' + file_name + '.csv')\n",
    "    print 'Results/' + effort['ID'] + ' - ' + file_name + '.csv'\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATS24*.3\n",
      "Performing alternate search for whistle midsection due to anomaly\n",
      "Search area modified due to whistle anomaly\n",
      "Best Curve Identified with freq 75.0 Hz and weight 46500.0\n",
      "Results/ATS24*.3 - 1459459078.202079.wav.csv\n",
      "ATS24*.4\n",
      "Best Curve Identified with freq 50.0 Hz and weight 29300.0\n",
      "Results/ATS24*.4 - 1459459128.589014.wav.csv\n",
      "ATS24*.17\n",
      "Best Curve Identified with freq 300.0 Hz and weight 31300.0\n",
      "Results/ATS24*.17 - 1459459735.092742.wav.csv\n",
      "ATS24*.22\n",
      "Best Curve Identified with freq 125.0 Hz and weight 42500.0\n",
      "Results/ATS24*.22 - 1459459910.151819.wav.csv\n",
      "ATS24*.23\n",
      "Search area modified due to whistle anomaly\n",
      "Best Curve Identified with freq 50.0 Hz and weight 43500.0\n",
      "Results/ATS24*.23 - 1459459966.974051.wav.csv\n",
      "ATS26.6\n",
      "Performing alternate search for whistle midsection due to anomaly\n",
      "Search area modified due to whistle anomaly\n",
      "Best Curve Identified with freq 75.0 Hz and weight 25400.0\n",
      "Results/ATS26.6 - 1459460168.352141.wav.csv\n",
      "ATS26.7\n",
      "Search area modified due to whistle anomaly\n",
      "Best Curve Identified with freq 150.0 Hz and weight 9100.0\n",
      "Results/ATS26.7 - 1459460201.121163.wav.csv\n",
      "ATS26.8\n",
      "Performing alternate search for whistle midsection due to anomaly\n",
      "Search area modified due to whistle anomaly\n",
      "Best Curve Identified with freq 75.0 Hz and weight 11800.0\n",
      "Results/ATS26.8 - 1459460234.857244.wav.csv\n",
      "ATS24*.20\n",
      "Best Curve Identified with freq 50.0 Hz and weight 38200.0\n",
      "Results/ATS24*.20 - 1459459875.252584.wav.csv\n",
      "ATS26.3\n",
      "Best Curve Identified with freq 125.0 Hz and weight 26300.0\n",
      "Results/ATS26.3 - 1459460060.495227.wav.csv\n",
      "ATS26.21\n",
      "Best Curve Identified with freq 50.0 Hz and weight 20300.0\n",
      "Results/ATS26.21 - 1459460581.229620.wav.csv\n",
      "ATS26.22\n",
      "Best Curve Identified with freq 50.0 Hz and weight 29200.0\n",
      "Results/ATS26.22 - 1459460618.998413.wav.csv\n",
      "ATS24*.8\n",
      "Best Curve Identified with freq 50.0 Hz and weight 29500.0\n",
      "Results/ATS24*.8 - 1459459269.076375.wav.csv\n",
      "ATS26.4\n",
      "Best Curve Identified with freq 50.0 Hz and weight 27000.0\n",
      "Results/ATS26.4 - 1459460094.564327.wav.csv\n",
      "ATS26.9\n",
      "Best Curve Identified with freq 175.0 Hz and weight 12700.0\n",
      "Results/ATS26.9 - 1459460269.642409.wav.csv\n",
      "ATS26.10\n",
      "Best Curve Identified with freq 75.0 Hz and weight 34800.0\n",
      "Results/ATS26.10 - 1459460302.994551.wav.csv\n",
      "\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = 'audio_curve_data/'\n",
    "# data_path = 'audio_curve_data/Final_Data/'\n",
    "\n",
    "# json_file = data_path + '105.json'\n",
    "json_file = data_path + '107.json'\n",
    "# json_file = data_path + '010.json'\n",
    "\n",
    "\n",
    "\n",
    "# json_105 = ['ATS24.3','ATS24*.3','ATS24.4','ATS24*.4','ATS24.11','ATS24.13','ATS24*.13','ATS24.15','ATS24*.15','ATS24.17','ATS24.22','ATS24.23','ATS24.24','ATS26*.6','ATS26.7','ATS26*.7','ATS26.8','ATS26*.8','ATS26.25','ATS26*.25','ATS24.20','ATS24*.20','ATS26*.3','ATS26.21','ATS26*.21','ATS26.22','ATS26*.22','ATS24.8','ATS24*.8','ATS24.12','ATS26.2','ATS26*.2','ATS26.4','ATS26*.4','ATS26*.9','ATS26.10','ATS26*.10','ATS26.19','ATS26*.19','ATS26.23','ATS26*.23']\n",
    "\n",
    "json_107 = ['ATS24.3','ATS24*.3','ATS24.4','ATS24*.4','ATS24.11','ATS24*.11','ATS24.13','ATS24.15','ATS24*.15','ATS24.17','ATS24*.17','ATS24.22','ATS24*.22','ATS24.23','ATS24*.23','ATS24.24','ATS26.6','ATS26*.6','ATS26.7','ATS26*.7','ATS26.8','ATS26*.8','ATS26.25','ATS26*.25','ATS24.20','ATS24*.20','ATS26.3','ATS26*.3','ATS26.21','ATS26*.21','ATS26.22','ATS26*.22','ATS24.8','ATS24*.8','ATS24.12','ATS26.2','ATS26*.2','ATS26.4','ATS26*.4','ATS26.9','ATS26*.9','ATS26.10','ATS26*.10','ATS26.19','ATS26*.19','ATS26.23','ATS26*.23','ATS26.26', 'ATS26*.26']\n",
    "\n",
    "# json_010 = ['ATS24.20','ATS26.3','ATS26.21','ATS26.22','ATS24.1','ATS24.2','ATS24.5','ATS24.6','ATS24.7','ATS24.8','ATS24.9','ATS24.10','ATS24.12','ATS24.14','ATS24.16','ATS24.18','ATS24.19','ATS24.21','ATS26.1','ATS26.2','ATS26.4','ATS26.5','ATS26.9','ATS26.10','ATS26.11','ATS26.12','ATS26.13','ATS26.14','ATS26.15','ATS26.16','ATS26.17','ATS26.18','ATS26.19','ATS26.20','ATS26.23','ATS26.24']\n",
    "\n",
    "# all_missing = ['ATS24.3','ATS24*.3','ATS24.4','ATS24*.4','ATS24.11','ATS24*.11','ATS24.13','ATS24*.13','ATS24.15','ATS24*.15','ATS24.17','ATS24*.17','ATS24.22','ATS24*.22','ATS24.23','ATS24*.23','ATS24.24','ATS24*.24','ATS26.6','ATS26*.6','ATS26.7','ATS26*.7','ATS26.8','ATS26*.8','ATS26.25','ATS26*.25','ATS24.20','ATS24*.20','ATS26.3','ATS26*.3','ATS26.21','ATS26*.21','ATS26.22','ATS26*.22','ATS24.8','ATS24*.8','ATS24.12','ATS24*.12','ATS26.2','ATS26*.2','ATS26.4','ATS26*.4','ATS26.9','ATS26*.9','ATS26.10','ATS26*.10','ATS26.19','ATS26*.19','ATS26.23','ATS26*.23','ATS26.26', 'ATS26*.26']\n",
    "\n",
    "\n",
    "tests_to_run = json_107\n",
    "# tests_to_run = ['ATS26.26', 'ATS26*.26']\n",
    "\n",
    "\n",
    "\n",
    "load_json_data(data_path, json_file)\n",
    "\n",
    "\n",
    "\n",
    "global sampling_rate, raw_data, sampling_rate_columns, wav_form, meta, effort, audio_files\n",
    "\n",
    "# file = audio_files_list[0]\n",
    "\n",
    "for test in tests_to_run:\n",
    "    if test in audio_files:\n",
    "        print test\n",
    "        effort = audio_files[test]\n",
    "        file_name = effort['WavFile']\n",
    "\n",
    "        sampling_rate, raw_data = wavfile.read(data_path + file_name)\n",
    "        sampling_rate_columns = sampling_rate / fft_shift\n",
    "        wav_form = read_waveform_data(effort['PWGFile'])\n",
    "        meta = effort['Metadata']\n",
    "\n",
    "        run_algorithm()\n",
    "\n",
    "\n",
    "print '\\n\\nFinished'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
